{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gfu2lLMpniSE"
   },
   "source": [
    "# ü¶Å CHULA Loss Demo on African Wildlife Detection  \n",
    "*Unlock the Future with Intelligent Machines* ü§ñ‚ú®\n",
    "\n",
    "> üå∏ **CHULA**: *Custom Heuristic Uncertainty-guided Loss for Accurate Land Title Deed Segmentation*  \n",
    "> üß† **Author**: Teerapong Panboonyuen (aka Kao Panboonyuen, ‡∏ò‡∏µ‡∏£‡∏û‡∏á‡∏®‡πå ‡∏õ‡∏≤‡∏ô‡∏ö‡∏∏‡∏ç‡∏¢‡∏∑‡∏ô, ‡πÄ‡∏Å‡πâ‡∏≤ ‡∏õ‡∏≤‡∏ô‡∏ö‡∏∏‡∏ç‡∏¢‡∏∑‡∏ô)  \n",
    "> üö© Supported by the Second Century Fund (C2F) Postdoctoral Fellowship, Chulalongkorn University  \n",
    "> üß™ Reproducible ‚Ä¢ Plug-and-Play ‚Ä¢ Open Source for Vision AI Research  \n",
    "> üéØ **CHULA now supports multiclass detection** ‚Äî demonstrated here on **African Wildlife** üêÉüêòü¶èü¶ì\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Note  \n",
    "Due to access restrictions on Thai Land Title Deed data, this demo showcases CHULA on a public dataset (african wildlife) to highlight its plug-and-play flexibility and generalization power.\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Links\n",
    "\n",
    "- üß¨ **GitHub Repository**: [kaopanboonyuen/CHULA](https://github.com/kaopanboonyuen/CHULA)  \n",
    "- üåê **Project Page**: [kaopanboonyuen.github.io/CHULA](https://kaopanboonyuen.github.io/CHULA)  \n",
    "- üìñ **Reference and Credit**: [Ultralytics Datasets Docs](https://docs.ultralytics.com/datasets/)\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Citation\n",
    "\n",
    "If you use CHULA in your research or projects, please cite:\n",
    "\n",
    "```\n",
    "\n",
    "@article{panboonyuen2025chula,\n",
    "title={CHULA: Custom Heuristic Uncertainty-guided Loss for Accurate Land Title Deed Segmentation},\n",
    "author={Panboonyuen, Teerapong},\n",
    "year={2025}\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### üìÑ License (MIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogSvEpB7goLz"
   },
   "source": [
    "![](https://www.animalspot.net/wp-content/uploads/2019/08/African-Animals-Images.jpg)\n",
    "\n",
    "> **Reference:**  \n",
    "> Animal Spot. (2025). *African Animals*. Retrieved from [https://www.animalspot.net/african-animals](https://www.animalspot.net/african-animals)\n",
    "\n",
    "\n",
    "![](https://struiknature.co.za/wp-content/uploads/2022/04/World-of-African-Wildlife-p32-33-scaled.webp)\n",
    "\n",
    "> **Reference:**  \n",
    "> Hendry, O. (2022). *World of African Wildlife* [Softcover]. Struik Nature. Retrieved from https://struiknature.co.za/product/world-of‚Äëafrican‚Äëwildlife/?srsltid=AfmBOop0avNDYziQSMW3RYyNklC9qjtGD0LixEJCGGSslUd904mus_JZ\n",
    "\n",
    "![](https://github.com/kaopanboonyuen/panboonyuen_dataset/raw/main/public_dataset/ultralytics_dataset/african-wildlife-dataset-sample.png)\n",
    "\n",
    "> **Reference:**  \n",
    "> Ultralytics. (n.d.). *Ultralytics Datasets: African Wildlife Detection Dataset*. AGPL‚Äë3.0. Retrieved from [https://docs.ultralytics.com/datasets/detect/african-wildlife/](https://docs.ultralytics.com/datasets/detect/african-wildlife/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5OpO4nbJluA"
   },
   "source": [
    "# ‚úÖ Step 1: Install YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzhyuKSxJl79",
    "outputId": "7d083635-9e9a-469f-d5c7-57e2a59c86a2"
   },
   "outputs": [],
   "source": [
    "!pip install # Please insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CajfeICvJoel"
   },
   "source": [
    "# ‚úÖ Step 2: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOSUxgeEJnk_",
    "outputId": "3518c985-8935-4a75-b3c6-1d4d3f03affa"
   },
   "outputs": [],
   "source": [
    "import os, zipfile, glob, random, cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ultralytics import # Please insert your code here.\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr1BgNsHJrEM"
   },
   "source": [
    "# üì• Step 3: Download African Wildlife Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGQEYu33JpyE",
    "outputId": "7e49758b-13d1-4947-8021-ff7410447e6c"
   },
   "outputs": [],
   "source": [
    "!wget -O african-wildlife.zip https://github.com/kaopanboonyuen/panboonyuen_dataset/raw/main/public_dataset/ultralytics_dataset/african-wildlife.zip\n",
    "\n",
    "dataset_dir = \"/content/datasets/african-wildlife\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(\"african-wildlife.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"/content/datasets/\")\n",
    "\n",
    "print(\"‚úÖ Dataset extracted to:\", dataset_dir)\n",
    "print(\"üìÇ Files inside:\", os.listdir(dataset_dir))\n",
    "\n",
    "with zipfile.ZipFile(\"african-wildlife.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"/content/datasets/african-wildlife\")\n",
    "\n",
    "print(\"‚úÖ Dataset extracted to:\", dataset_dir)\n",
    "print(\"üìÇ Files inside:\", os.listdir(dataset_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8gwPysRJvop"
   },
   "source": [
    "# üìù Step 4: Rewrite african-wildlife.yaml for Colab path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UJJ7RpHJuVJ",
    "outputId": "6e2b22a8-a3c3-46aa-d3c4-a650dc3ca8e8"
   },
   "outputs": [],
   "source": [
    "yaml_content = f\"\"\"# African Wildlife Dataset (Ultralytics format)\n",
    "path: {dataset_dir}\n",
    "\n",
    "train: images/train\n",
    "val: images/val\n",
    "test:\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: buffalo\n",
    "  1: elephant\n",
    "  2: rhino\n",
    "  3: zebra\n",
    "\n",
    "download: https://github.com/kaopanboonyuen/panboonyuen_dataset/raw/main/public_dataset/ultralytics_dataset/african-wildlife.zip\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(dataset_dir, \"african-wildlife.yaml\"), \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"‚úÖ Rewritten african-wildlife.yaml\")\n",
    "!cat /content/datasets/african-wildlife/african-wildlife.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXb2T1JAJyhA"
   },
   "source": [
    "# üëÄ Step 5: Preview dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "0XcYCe4FJytB",
    "outputId": "355fbf91-94d6-4e3c-eef1-5e7a743adb9f"
   },
   "outputs": [],
   "source": [
    "train_images = glob.glob(os.path.join(dataset_dir, \"african-wildlife/images/train/*.jpg\"))\n",
    "sample_images = random.sample(train_images, 4)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, img_path in enumerate(sample_images):\n",
    "    img = cv2.imread(img_path)[..., ::-1]\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Train Sample {i+1}\")\n",
    "\n",
    "# Please insert your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmIjLJ7lJ02w"
   },
   "source": [
    "# üöÄ Step 6: Train YOLOv8 on African Wildlife Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfEM01CS7jJY"
   },
   "source": [
    "## CHULA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBgLzzPPDM2A",
    "outputId": "32f50c26-2f9c-4d35-da95-12e7e38b9124"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/kaopanboonyuen/CHULA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYr4Y7zXDlhg"
   },
   "outputs": [],
   "source": [
    "!pip install -e CHULA >> log_chula.logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVW22n10DMvR"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/CHULA')\n",
    "\n",
    "from chula.loss import CHULALoss\n",
    "from chula.utils import compute_class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5OhIntR7XqK"
   },
   "source": [
    "## CHULA Loss Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmgCveg_7lKe"
   },
   "outputs": [],
   "source": [
    "dataset_dir = \"/content/datasets/african-wildlife\"\n",
    "\n",
    "num_classes = 4  # buffalo, elephant, rhino, zebra\n",
    "class_weights = compute_class_weights(dataset_dir, num_classes).cuda()\n",
    "chula_loss = CHULALoss(class_weights=class_weights, lambda_ce=1.0, lambda_unc=0.3, lambda_heu=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HBsDuFz77oy"
   },
   "source": [
    "## Train YOLOv8 Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtycYlziJ2BU",
    "outputId": "c1e883dd-1afc-4a38-861e-e12fde9ec11a"
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Train YOLOv8 Original\n",
    "# --------------------------\n",
    "model_orig = YOLO(\"# Please insert your code here.\")\n",
    "results_orig = model_orig.train(\n",
    "    data=f\"{dataset_dir}/african-wildlife.yaml\",\n",
    "    epochs=3,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name=\"yolo_african_wildlife_orig\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG6nV8b68cXl",
    "outputId": "b2c11b75-00a1-4a75-b4e4-6eed5ea5570e"
   },
   "outputs": [],
   "source": [
    "results_orig = model_orig.val(save=False, plots=False)\n",
    "\n",
    "# Option 1: dictionary of results\n",
    "metrics_orig = results_orig.results_dict\n",
    "print(\"üìä Original YOLOv8 metrics:\", metrics_orig)\n",
    "\n",
    "# Option 2: precision, recall, mAP\n",
    "precision, recall, map50, map50_95 = results_orig.mean_results()\n",
    "print(f\"Precision={precision:.3f}, Recall={recall:.3f}, mAP50={map50:.3f}, mAP50-95={map50_95:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BK-_PPG07-dh"
   },
   "source": [
    "## Train YOLOv8 + CHULA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40CyFtfM8DKE",
    "outputId": "fc0fd8ac-ab1e-48f7-989f-4db277ca9eb8"
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Train YOLOv8 + CHULA\n",
    "# --------------------------\n",
    "model_chula = YOLO(\"# Please insert your code here.\")\n",
    "\n",
    "# Patch YOLO internal loss\n",
    "original_loss = model_chula.model.loss\n",
    "def patched_loss(preds, targets, imgs=None):\n",
    "    yolo_loss = original_loss(preds, targets, imgs)\n",
    "    sigma = torch.rand_like(targets.unsqueeze(1)) * 0.1\n",
    "    heuristic_masks = {cls: targets==cls for cls in range(num_classes)}\n",
    "    chula_term = chula_loss(preds, targets, sigma=sigma, heuristic_masks=heuristic_masks)\n",
    "    return yolo_loss + 0.5 * chula_term\n",
    "\n",
    "model_chula.model.loss = patched_loss\n",
    "\n",
    "results_chula = model_chula.train(\n",
    "    data=f\"{dataset_dir}/african-wildlife.yaml\",\n",
    "    epochs=3,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name=\"yolo_african_wildlife_chula\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPE9IzIo8FAi",
    "outputId": "a399a92e-3b14-432d-be21-23f85584c239"
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Evaluate Original YOLOv8\n",
    "# --------------------------\n",
    "results_orig = model_orig.val(save=False, plots=False)\n",
    "metrics_orig = results_orig.results_dict\n",
    "print(\"üìä Original YOLOv8 metrics:\", metrics_orig)\n",
    "\n",
    "# --------------------------\n",
    "# Evaluate YOLOv8 + CHULA\n",
    "# --------------------------\n",
    "results_chula = model_chula.val(save=False, plots=False)\n",
    "metrics_chula = results_chula.results_dict\n",
    "print(\"üìä YOLOv8 + CHULA metrics:\", metrics_chula)\n",
    "\n",
    "# --------------------------\n",
    "# Optional: Unpack mean results (precision, recall, mAP)\n",
    "# --------------------------\n",
    "prec_o, rec_o, map50_o, map95_o = results_orig.mean_results()\n",
    "prec_c, rec_c, map50_c, map95_c = results_chula.mean_results()\n",
    "\n",
    "print(f\"Original: P={prec_o:.3f}, R={rec_o:.3f}, mAP50={map50_o:.3f}, mAP50-95={map95_o:.3f}\")\n",
    "print(f\"CHULA:    P={prec_c:.3f}, R={rec_c:.3f}, mAP50={map50_c:.3f}, mAP50-95={map95_c:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2duLivgm8IDI"
   },
   "source": [
    "## Compare & Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "FDOrBTFu8K_m",
    "outputId": "3dffe87d-a8ab-410e-d7d1-3acf51e582e7"
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Compare & Plot Metrics\n",
    "# --------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract from results_dict\n",
    "def extract_metrics(results_dict):\n",
    "    precision = results_dict.get(\"metrics/precision(B)\", 0.0)\n",
    "    recall = results_dict.get(\"metrics/recall(B)\", 0.0)\n",
    "    map50 = results_dict.get(\"metrics/mAP50(B)\", 0.0)\n",
    "    map95 = results_dict.get(\"metrics/mAP50-95(B)\", 0.0)\n",
    "    # F1 from precision & recall\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    return precision, recall, map50, map95, f1\n",
    "\n",
    "# Get values\n",
    "prec_o, rec_o, map50_o, map95_o, f1_o = extract_metrics(metrics_orig)\n",
    "prec_c, rec_c, map50_c, map95_c, f1_c = extract_metrics(metrics_chula)\n",
    "\n",
    "labels = [\"Precision\", \"Recall\", \"mAP50\", \"mAP50-95\", \"F1\"]\n",
    "orig_vals = [prec_o, rec_o, map50_o, map95_o, f1_o]\n",
    "chula_vals = [prec_c, rec_c, map50_c, map95_c, f1_c]\n",
    "\n",
    "# Plot side-by-side bars\n",
    "x = range(len(labels))\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar([i-0.15 for i in x], orig_vals, width=0.3, label=\"YOLOv8 Original\")\n",
    "plt.bar([i+0.15 for i in x], chula_vals, width=0.3, label=\"YOLOv8 + CHULA\")\n",
    "plt.xticks(x, labels, fontsize=12)\n",
    "plt.ylabel(\"Metric Score\", fontsize=12)\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"YOLOv8 vs YOLOv8 + CHULA Loss on African Wildlife\", fontsize=14, weight=\"bold\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ6DC189J3VE"
   },
   "source": [
    "# üìä Step 7: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "id": "HyzKyV44J4jb",
    "outputId": "b4030440-77b2-40f0-8b61-9123bcb5a8cf"
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join(model_chula.trainer.save_dir, \"results.png\")\n",
    "if os.path.exists(results_path):\n",
    "    display(Image(filename=results_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT4DoRY5J52z"
   },
   "source": [
    "# üìà Step 8: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "w6hlBwU_J7B3",
    "outputId": "68b692cf-4877-4a4d-8322-50c0ca031f25"
   },
   "outputs": [],
   "source": [
    "metrics = model_chula.val(save=True, plots=True)\n",
    "print(\"‚úÖ Evaluation metrics:\", metrics)\n",
    "\n",
    "eval_dir = model_chula.trainer.save_dir\n",
    "for plot_name in [\"confusion_matrix.png\", \"PR_curve.png\", \"F1_curve.png\"]:\n",
    "    plot_path = os.path.join(eval_dir, plot_name)\n",
    "    if os.path.exists(plot_path):\n",
    "        display(Image(filename=plot_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_KiZiN3J90N"
   },
   "source": [
    "# üîÆ Step 9: Inference on a Random Validation Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "id": "7bfY9LnMJ-Oe",
    "outputId": "5b398f10-68c2-4d87-9ef5-1ed122658094"
   },
   "outputs": [],
   "source": [
    "val_images = glob.glob(os.path.join(dataset_dir, \"# Please insert your dataset path here.\"))\n",
    "test_img = random.choice(val_images)\n",
    "\n",
    "# Run inference and save output\n",
    "results = model_chula(test_img, save=True)\n",
    "print(\"üîç Prediction done on:\", test_img)\n",
    "\n",
    "# ‚úÖ Correct way to get saved prediction image path\n",
    "pred_dir = results[0].save_dir  # directory YOLO saved results\n",
    "pred_img = os.path.join(pred_dir, os.path.basename(results[0].path))\n",
    "\n",
    "display(Image(filename=pred_img))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
